{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example for implementation of image recognition library\n",
    "\n",
    "### First check requirement.txt and make sure to pip install required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now lets import the classifier library so we can test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ai_image_classifier as ai\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement classifier in 4 lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model\n",
      "Epoch 0/4\n",
      "----------\n",
      "train Loss: 0.4559 Acc: 0.7807\n",
      "val Loss: 0.2095 Acc: 0.9192\n",
      "Epoch 1/4\n",
      "----------\n",
      "train Loss: 0.4074 Acc: 0.8505\n",
      "val Loss: 0.6327 Acc: 0.8586\n",
      "Epoch 2/4\n",
      "----------\n",
      "train Loss: 0.6331 Acc: 0.8272\n",
      "val Loss: 0.1429 Acc: 0.9697\n",
      "Epoch 3/4\n",
      "----------\n",
      "train Loss: 0.2609 Acc: 0.9269\n",
      "val Loss: 0.1097 Acc: 0.9798\n",
      "Epoch 4/4\n",
      "----------\n",
      "train Loss: 0.5153 Acc: 0.8771\n",
      "val Loss: 0.0551 Acc: 0.9899\n",
      "Training complete in 1m 57s\n",
      "Best val Acc: 0.989899\n",
      "model saved\n",
      "model trained with accuracy of : 0.98989898989899%\n"
     ]
    }
   ],
   "source": [
    "path_dataset = './dataset_for_example'\n",
    "ai.load_data(path_dataset)                                      # define the path for the dataset folder\n",
    "model, accuracy = ai.load_and_train_model(epochs=5)             # Train model 5 epochs will be enough \n",
    "                                                                #- 7 to 9 epochs for more complex problems with less data\n",
    "                                                                # and/or more classes\n",
    "ai.save_model(model, name='example')                            # save model\n",
    "print('model trained with accuracy of : {}%'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model and test on single image\n",
    "### First on a Pear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- The image is: pear\n"
     ]
    }
   ],
   "source": [
    "model = ai.load_model('example')                              # load model\n",
    "image_pear = ai.load_one_image('./test_pear.jpeg')            # load image as tensor\n",
    "path_dataset = './dataset_for_example'\n",
    "\n",
    "output = model(image_pear)                                    # generate prediction for pear\n",
    "_, preds = torch.max(output, 1)                   \n",
    "classes_names = ai.get_classes_array(path_dataset)                        # get the names of the classes that have been classified. i.e. oranges, etc\n",
    "for i in preds:\n",
    "    print('- The image is: {}'.format(classes_names[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second is an orange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- The image is: orange\n"
     ]
    }
   ],
   "source": [
    "model = ai.load_model('example')                              # load model\n",
    "image_orange = ai.load_one_image('./test_orange.jpeg')          # load image as tensor\n",
    "path_dataset = './dataset_for_example'\n",
    "\n",
    "output = model(image_orange)                                    # generate prediction for pear\n",
    "_, preds = torch.max(output, 1)                   \n",
    "classes_names = ai.get_classes_array(path_dataset)                        # get the names of the classes that have been classified. i.e. oranges, etc\n",
    "for i in preds:\n",
    "    print('- The image is: {}'.format(classes_names[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And that's the end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
